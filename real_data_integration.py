"""
Integration module to replace dummy data with real data in ProjectP pipeline
=========================================================================

This module integrates the real data loader into the existing ProjectP pipeline
"""

import os
import pandas as pd
from typing import Dict, Any, Optional, Tuple
from real_data_loader import load_real_trading_data

def integrate_real_data_to_pipeline():
    """
    ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö pipeline
    """
    print("üöÄ INTEGRATING REAL DATA INTO PIPELINE")
    print("=" * 60)
    
    try:
        # 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á M15 (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö production)
        print("üìä Loading real M15 data...")
        df_m15, info_m15 = load_real_trading_data(
            timeframe="M15",
            max_rows=50000,  # ‡πÉ‡∏ä‡πâ 50k ‡πÅ‡∏ñ‡∏ß‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô
            profit_threshold=0.12  # ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≥‡πÑ‡∏£ 0.12%
        )
        
        # 2. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå
        output_dir = "output_default"
        os.makedirs(output_dir, exist_ok=True)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏Å
        real_data_path = os.path.join(output_dir, "real_trading_data.csv")
        df_m15.to_csv(real_data_path, index=False)
        print(f"üíæ Saved real data to: {real_data_path}")
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö training/testing
        features_path = os.path.join(output_dir, "features.csv")
        targets_path = os.path.join(output_dir, "targets.csv")
        
        feature_cols = [col for col in df_m15.columns if col not in 
                       ['Time', 'target', 'target_binary', 'target_return']]
        target_cols = ['target', 'target_binary', 'target_return']
        
        df_m15[feature_cols].to_csv(features_path, index=False)
        df_m15[target_cols].to_csv(targets_path, index=False)
        
        print(f"üíæ Saved features to: {features_path}")
        print(f"üíæ Saved targets to: {targets_path}")
        
        # 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
        stats = {
            'data_source': 'XAUUSD_M15.csv (Real Market Data)',
            'total_samples': len(df_m15),
            'feature_count': len(feature_cols),
            'time_range': {
                'start': df_m15['Time'].min().isoformat(),
                'end': df_m15['Time'].max().isoformat()
            },
            'price_range': {
                'min': float(df_m15['Close'].min()),
                'max': float(df_m15['Close'].max())
            },
            'target_distribution': info_m15['target_distribution'],
            'class_balance': {
                'hold_pct': info_m15['target_distribution'].get(0, 0) / len(df_m15) * 100,
                'buy_pct': info_m15['target_distribution'].get(1, 0) / len(df_m15) * 100,
                'sell_pct': info_m15['target_distribution'].get(2, 0) / len(df_m15) * 100
            }
        }
        
        import json
        stats_path = os.path.join(output_dir, "real_data_stats.json")
        with open(stats_path, 'w') as f:
            json.dump(stats, f, indent=2)
        print(f"üìä Saved statistics to: {stats_path}")
        
        # 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô pipeline
        create_pipeline_data_loader()
        
        print("\n‚úÖ REAL DATA INTEGRATION COMPLETED!")
        print(f"‚úÖ Real data samples: {len(df_m15):,}")
        print(f"‚úÖ Features: {len(feature_cols)}")
        print(f"‚úÖ Time range: {df_m15['Time'].min()} to {df_m15['Time'].max()}")
        print(f"‚úÖ Target balance: Buy {stats['class_balance']['buy_pct']:.1f}% | Sell {stats['class_balance']['sell_pct']:.1f}% | Hold {stats['class_balance']['hold_pct']:.1f}%")
        
        return True, stats
        
    except Exception as e:
        print(f"‚ùå Failed to integrate real data: {e}")
        import traceback
        traceback.print_exc()
        return False, None

def create_pipeline_data_loader():
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå data loader ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á"""
    
    loader_code = '''"""
Pipeline Data Loader - ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡πÅ‡∏ó‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
=================================================
"""

import pandas as pd
import numpy as np
import os
from typing import Tuple, Dict, Any, Optional

def load_pipeline_data(output_dir: str = "output_default") -> Tuple[pd.DataFrame, pd.DataFrame, Dict[str, Any]]:
    """
    ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö pipeline
    
    Returns:
        features_df: DataFrame ‡∏Ç‡∏≠‡∏á features
        targets_df: DataFrame ‡∏Ç‡∏≠‡∏á targets  
        stats: ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    """
    try:
        # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        features_path = os.path.join(output_dir, "features.csv")
        targets_path = os.path.join(output_dir, "targets.csv")
        stats_path = os.path.join(output_dir, "real_data_stats.json")
        
        if not all(os.path.exists(p) for p in [features_path, targets_path, stats_path]):
            print("üîÑ Real data not found, generating...")
            from real_data_integration import integrate_real_data_to_pipeline
            success, stats = integrate_real_data_to_pipeline()
            if not success:
                raise FileNotFoundError("Failed to generate real data")
        
        # ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå
        features_df = pd.read_csv(features_path)
        targets_df = pd.read_csv(targets_path)
        
        import json
        with open(stats_path, 'r') as f:
            stats = json.load(f)
        
        print(f"‚úÖ Loaded real trading data: {len(features_df):,} samples, {len(features_df.columns)} features")
        
        return features_df, targets_df, stats
        
    except Exception as e:
        print(f"‚ùå Error loading pipeline data: {e}")
        # Fallback ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
        return create_fallback_data()

def create_fallback_data() -> Tuple[pd.DataFrame, pd.DataFrame, Dict[str, Any]]:
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏Å‡∏£‡∏ì‡∏µ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ"""
    print("‚ö†Ô∏è Using fallback dummy data")
    
    np.random.seed(42)
    n_samples = 1000
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á features
    features_df = pd.DataFrame({
        'feature_1': np.random.randn(n_samples),
        'feature_2': np.random.randn(n_samples),
        'feature_3': np.random.randn(n_samples),
        'price': 1800 + np.random.randn(n_samples) * 50,
        'volume': np.random.uniform(0.1, 1.0, n_samples)
    })
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á targets
    targets_df = pd.DataFrame({
        'target': np.random.choice([0, 1, 2], n_samples, p=[0.5, 0.25, 0.25]),
        'target_binary': np.random.choice([0, 1], n_samples, p=[0.6, 0.4]),
        'target_return': np.random.randn(n_samples) * 0.1
    })
    
    stats = {
        'data_source': 'Fallback dummy data',
        'total_samples': n_samples,
        'feature_count': len(features_df.columns)
    }
    
    return features_df, targets_df, stats

# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡πÅ‡∏ó‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
def get_base_data(*args, **kwargs):
    """‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á"""
    features_df, targets_df, stats = load_pipeline_data()
    
    # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô DataFrame ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    df = pd.concat([features_df, targets_df], axis=1)
    df['target'] = targets_df['target']
    
    return df

def load_main_training_data(*args, **kwargs):
    """‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ó‡∏£‡∏ô‡∏ô‡∏¥‡πà‡∏á‡πÄ‡∏î‡∏¥‡∏°"""
    return get_base_data(*args, **kwargs)

# Monkey patch ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö compatibility
import sys
if 'projectp.utils_data' in sys.modules:
    projectp_utils_data = sys.modules['projectp.utils_data']
    projectp_utils_data.load_main_training_data = load_main_training_data
    projectp_utils_data.get_base_data = get_base_data

if __name__ == "__main__":
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    features_df, targets_df, stats = load_pipeline_data()
    print(f"Features shape: {features_df.shape}")
    print(f"Targets shape: {targets_df.shape}")
    print(f"Stats: {stats}")
'''
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå
    with open("pipeline_data_loader.py", "w", encoding="utf-8") as f:
        f.write(loader_code)
    
    print("üìÅ Created pipeline_data_loader.py")

def patch_projectp_for_real_data():
    """‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á ProjectP.py ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á"""
    
    patch_code = '''
# ===== REAL DATA INTEGRATION PATCH =====
# ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á

print("üîÑ Patching ProjectP to use real data...")
try:
    from pipeline_data_loader import load_pipeline_data, get_base_data, load_main_training_data
    
    # Monkey patch ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á
    import sys
    
    # ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô projectp.utils_data ‡∏´‡∏≤‡∏Å‡∏°‡∏µ
    if 'projectp.utils_data' in sys.modules:
        utils_data = sys.modules['projectp.utils_data']
        utils_data.load_main_training_data = load_main_training_data
        utils_data.get_base_data = get_base_data
        print("‚úÖ Patched projectp.utils_data")
    
    # ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô projectp.utils_data_csv ‡∏´‡∏≤‡∏Å‡∏°‡∏µ  
    if 'projectp.utils_data_csv' in sys.modules:
        utils_data_csv = sys.modules['projectp.utils_data_csv']
        utils_data_csv.load_and_prepare_main_csv = load_main_training_data
        print("‚úÖ Patched projectp.utils_data_csv")
    
    print("üéØ Real data integration patch applied successfully!")
    
except ImportError as e:
    print(f"‚ö†Ô∏è Could not patch for real data: {e}")
    print("üìã Continuing with existing data source...")

# ===== END REAL DATA INTEGRATION PATCH =====
'''
    
    return patch_code

if __name__ == "__main__":
    print("üöÄ Starting Real Data Integration")
    success, stats = integrate_real_data_to_pipeline()
    
    if success:
        print("\nüéâ INTEGRATION SUCCESSFUL!")
        print("üìã Next Steps:")
        print("1. ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ô output_default/")
        print("2. ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏±‡∏ô ProjectP.py ‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏õ‡∏Å‡∏ï‡∏¥")
        print("3. ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡πÅ‡∏ó‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
        if stats:
            print(f"\nüìä Data Statistics:")
            print(f"   - Samples: {stats['total_samples']:,}")
            print(f"   - Features: {stats['feature_count']}")
            print(f"   - Time range: {stats['time_range']['start']} to {stats['time_range']['end']}")
            print(f"   - Price range: ${stats['price_range']['min']:.2f} - ${stats['price_range']['max']:.2f}")
    else:
        print("\n‚ùå INTEGRATION FAILED!")
        print("‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏ó‡∏ô")
