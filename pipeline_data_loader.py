"""
Pipeline Data Loader - ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡πÅ‡∏ó‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
=================================================
"""

import pandas as pd
import numpy as np
import os
from typing import Tuple, Dict, Any, Optional

def load_pipeline_data(output_dir: str = "output_default") -> Tuple[pd.DataFrame, pd.DataFrame, Dict[str, Any]]:
    """
    ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö pipeline
    
    Returns:
        features_df: DataFrame ‡∏Ç‡∏≠‡∏á features
        targets_df: DataFrame ‡∏Ç‡∏≠‡∏á targets  
        stats: ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    """
    try:
        # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        features_path = os.path.join(output_dir, "features.csv")
        targets_path = os.path.join(output_dir, "targets.csv")
        stats_path = os.path.join(output_dir, "real_data_stats.json")
        
        if not all(os.path.exists(p) for p in [features_path, targets_path, stats_path]):
            print("üîÑ Real data not found, generating...")
            from real_data_integration import integrate_real_data_to_pipeline
            success, stats = integrate_real_data_to_pipeline()
            if not success:
                raise FileNotFoundError("Failed to generate real data")
        
        # ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå
        features_df = pd.read_csv(features_path)
        targets_df = pd.read_csv(targets_path)
        
        import json
        with open(stats_path, 'r') as f:
            stats = json.load(f)
        
        print(f"‚úÖ Loaded real trading data: {len(features_df):,} samples, {len(features_df.columns)} features")
        
        return features_df, targets_df, stats
        
    except Exception as e:
        print(f"‚ùå Error loading pipeline data: {e}")
        # Fallback ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
        return create_fallback_data()

def create_fallback_data() -> Tuple[pd.DataFrame, pd.DataFrame, Dict[str, Any]]:
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏Å‡∏£‡∏ì‡∏µ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ"""
    print("‚ö†Ô∏è Using fallback dummy data")
    
    np.random.seed(42)
    n_samples = 1000
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á features
    features_df = pd.DataFrame({
        'feature_1': np.random.randn(n_samples),
        'feature_2': np.random.randn(n_samples),
        'feature_3': np.random.randn(n_samples),
        'price': 1800 + np.random.randn(n_samples) * 50,
        'volume': np.random.uniform(0.1, 1.0, n_samples)
    })
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á targets
    targets_df = pd.DataFrame({
        'target': np.random.choice([0, 1, 2], n_samples, p=[0.5, 0.25, 0.25]),
        'target_binary': np.random.choice([0, 1], n_samples, p=[0.6, 0.4]),
        'target_return': np.random.randn(n_samples) * 0.1
    })
    
    stats = {
        'data_source': 'Fallback dummy data',
        'total_samples': n_samples,
        'feature_count': len(features_df.columns)
    }
    
    return features_df, targets_df, stats

# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡πÅ‡∏ó‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
def get_base_data(*args, **kwargs):
    """‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á"""
    features_df, targets_df, stats = load_pipeline_data()
    
    # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô DataFrame ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    df = pd.concat([features_df, targets_df], axis=1)
    df['target'] = targets_df['target']
    
    return df

def load_main_training_data(*args, **kwargs):
    """‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ó‡∏£‡∏ô‡∏ô‡∏¥‡πà‡∏á‡πÄ‡∏î‡∏¥‡∏°"""
    return get_base_data(*args, **kwargs)

# Monkey patch ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö compatibility
import sys
if 'projectp.utils_data' in sys.modules:
    projectp_utils_data = sys.modules['projectp.utils_data']
    projectp_utils_data.load_main_training_data = load_main_training_data
    projectp_utils_data.get_base_data = get_base_data

if __name__ == "__main__":
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    features_df, targets_df, stats = load_pipeline_data()
    print(f"Features shape: {features_df.shape}")
    print(f"Targets shape: {targets_df.shape}")
    print(f"Stats: {stats}")
