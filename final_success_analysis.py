#!/usr/bin/env python3
import json
import numpy as np
import os
import pandas as pd
"""
üéâ FINAL SUCCESS ANALYSIS
‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
"""


def main():
    """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢"""
    print("üéâ FINAL SUCCESS ANALYSIS")
    print(" = " * 80)

    # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå WalkForward Results
    analyze_walkforward_results()

    # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Threshold Results
    analyze_threshold_results()

    # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏£‡∏ß‡∏°
    final_summary()

def analyze_walkforward_results():
    """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå WalkForward"""
    print("\nüîç WALKFORWARD VALIDATION RESULTS")
    print(" - " * 50)

    try:
        df = pd.read_csv("output_default/walkforward_metrics.csv")
        print(f"üìä Total folds: {len(df)}")

        # ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ AUC
        auc_test = df['auc_test']
        auc_mean = auc_test.mean()
        auc_std = auc_test.std()
        auc_min = auc_test.min()
        auc_max = auc_test.max()

        print(f"üéØ AUC Test Results:")
        print(f"   Mean: {auc_mean:.4f}")
        print(f"   Std:  {auc_std:.4f}")
        print(f"   Min:  {auc_min:.4f}")
        print(f"   Max:  {auc_max:.4f}")

        # ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ Accuracy
        acc_test = df['acc_test']
        acc_mean = acc_test.mean()
        acc_std = acc_test.std()
        acc_min = acc_test.min()
        acc_max = acc_test.max()

        print(f"üìà Accuracy Test Results:")
        print(f"   Mean: {acc_mean:.4f}")
        print(f"   Std:  {acc_std:.4f}")
        print(f"   Min:  {acc_min:.4f}")
        print(f"   Max:  {acc_max:.4f}")

        # ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        if auc_mean >= 0.75:
            print("‚úÖ AUC: EXCELLENT (‚â• 0.75)")
        elif auc_mean >= 0.7:
            print("‚úÖ AUC: GOOD (‚â• 0.70)")
        elif auc_mean >= 0.65:
            print("‚ö†Ô∏è AUC: ACCEPTABLE (‚â• 0.65)")
        else:
            print("‚ùå AUC: NEEDS IMPROVEMENT (< 0.65)")

        if acc_mean >= 0.95:
            print("‚úÖ Accuracy: EXCELLENT (‚â• 95%)")
        elif acc_mean >= 0.9:
            print("‚úÖ Accuracy: GOOD (‚â• 90%)")
        else:
            print("‚ö†Ô∏è Accuracy: Needs improvement")

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Overfitting
        train_aucs = df['auc_train']
        train_test_gap = (train_aucs - auc_test).mean()
        print(f"üé≤ Overfitting Analysis:")
        print(f"   Train - Test AUC Gap: {train_test_gap:.4f}")

        if train_test_gap > 0.15:
            print("‚ö†Ô∏è High overfitting detected")
        elif train_test_gap > 0.1:
            print("‚ö†Ô∏è Moderate overfitting")
        else:
            print("‚úÖ Low overfitting")

    except Exception as e:
        print(f"‚ùå Error analyzing walkforward: {e}")

def analyze_threshold_results():
    """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå Threshold Optimization"""
    print("\nüéØ THRESHOLD OPTIMIZATION RESULTS")
    print(" - " * 50)

    try:
        # ‡∏≠‡πà‡∏≤‡∏ô summary metrics
        with open("models/threshold_summary_metrics.json", 'r') as f:
            threshold_data = json.load(f)

        print(f"üéØ Best Threshold: {threshold_data.get('best_threshold', 'N/A')}")
        print(f"üìä Best AUC: {threshold_data.get('best_auc', 'N/A')}")
        print(f"üìà Best Accuracy: {threshold_data.get('best_accuracy', 'N/A')}")

        # ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô threshold
        best_threshold = threshold_data.get('best_threshold', 0.5)
        if 0.1 <= best_threshold <= 0.4:
            print("‚úÖ Threshold in good range (0.1 - 0.4)")
        elif 0.4 < best_threshold <= 0.6:
            print("‚ö†Ô∏è Threshold moderate (0.4 - 0.6)")
        else:
            print("‚ö†Ô∏è Threshold unusual - may need review")

    except Exception as e:
        print(f"‚ùå Error analyzing threshold: {e}")

def final_summary():
    """‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏£‡∏ß‡∏°‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢"""
    print("\nüèÜ FINAL SUMMARY")
    print(" = " * 80)

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
    important_files = [
        ("output_default/walkforward_metrics.csv", "WalkForward Results"), 
        ("models/threshold_results.csv", "Threshold Results"), 
        ("output_default/preprocessed_super.parquet", "Processed Data"), 
        ("models/threshold_summary_metrics.json", "Threshold Summary"), 
        ("output_default/walkforward_summary_metrics.json", "WalkForward Summary")
    ]

    print("üìÅ Important Files Status:")
    all_files_exist = True
    for file_path, description in important_files:
        if os.path.exists(file_path):
            size = os.path.getsize(file_path)
            print(f"   ‚úÖ {description}: {size:, } bytes")
        else:
            print(f"   ‚ùå {description}: Missing")
            all_files_exist = False

    # ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°
    print("\nüéâ OVERALL SUCCESS ASSESSMENT:")

    success_factors = []

    # 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö WalkForward
    try:
        df = pd.read_csv("output_default/walkforward_metrics.csv")
        auc_mean = df['auc_test'].mean()
        if auc_mean >= 0.75:
            success_factors.append("‚úÖ Excellent WalkForward AUC")
        elif auc_mean >= 0.7:
            success_factors.append("‚úÖ Good WalkForward AUC")
        else:
            success_factors.append("‚ö†Ô∏è Moderate WalkForward AUC")
    except:
        success_factors.append("‚ùå WalkForward issues")

    # 2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå
    if all_files_exist:
        success_factors.append("‚úÖ All important files generated")
    else:
        success_factors.append("‚ö†Ô∏è Some files missing")

    # 3. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Class Imbalance Resolution
    if os.path.exists("output_default/preprocessed_super.parquet"):
        success_factors.append("‚úÖ Data preprocessing completed")

    print("\nüìã Success Factors:")
    for factor in success_factors:
        print(f"   {factor}")

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Success Score
    success_score = len([f for f in success_factors if f.startswith("‚úÖ")])
    total_factors = len(success_factors)
    success_percentage = (success_score / total_factors) * 100

    print(f"\nüèÜ SUCCESS SCORE: {success_score}/{total_factors} ({success_percentage:.1f}%)")

    if success_percentage >= 90:
        print("üéâ OUTSTANDING SUCCESS! üéâ")
        print("   All critical issues resolved")
        print("   Production ready!")
    elif success_percentage >= 75:
        print("‚úÖ GOOD SUCCESS!")
        print("   Most issues resolved")
        print("   Minor improvements may be needed")
    elif success_percentage >= 60:
        print("‚ö†Ô∏è MODERATE SUCCESS")
        print("   Some issues remain")
        print("   Additional work recommended")
    else:
        print("‚ùå NEEDS MORE WORK")
        print("   Significant issues remain")

    print("\n" + " = " * 80)
    print("üöÄ NICEGOLD TRADING SYSTEM STATUS: ANALYSIS COMPLETE")

if __name__ == "__main__":
    main()