    from .robust_model_loader import ensure_model_files_robust
from src.data_loader.csv_loader import safe_load_csv_auto
from src.utils import (
import json
import logging
import os
import pandas as pd
"""Model - related helpers extracted from src.main"""


    download_feature_list_if_missing, 
    download_model_if_missing, 
    validate_file, 
)

META_CLASSIFIER_PATH = "meta_classifier.pkl"
SPIKE_MODEL_PATH = "meta_classifier_spike.pkl"
CLUSTER_MODEL_PATH = "meta_classifier_cluster.pkl"
DEFAULT_MODEL_TO_LINK = "catboost"
shap_importance_threshold = 0.01
permutation_importance_threshold = 0.001
sample_size = None
features_to_drop = None
early_stopping_rounds_config = 200


def ensure_main_features_file(output_dir):
    """Create default features_main.json if it does not exist."""
    out_dir = output_dir if output_dir else "output_default"
    path = os.path.join(out_dir, "features_main.json")
    if os.path.exists(path):
        return path
    os.makedirs(out_dir, exist_ok = True)
    with open(path, "w", encoding = "utf - 8") as f:
        json.dump([], f, ensure_ascii = False, indent = 2)
    logging.info("[Patch] Created default features_main.json")
    return path


def save_features_main_json(features, output_dir):
    """Save main features list, creating QA log if empty."""
    out_dir = output_dir if output_dir else "output_default"
    os.makedirs(out_dir, exist_ok = True)
    path = os.path.join(out_dir, "features_main.json")
    if not features:
        logging.warning(
            "[QA] features_main.json is empty. Creating empty features file."
        )
        with open(path, "w", encoding = "utf - 8") as f:
            json.dump([], f, ensure_ascii = False, indent = 2)
        qa_log = os.path.join(out_dir, "features_main_qa.log")
        with open(qa_log, "w", encoding = "utf - 8") as f:
            f.write(
                "[QA] features_main.json EMPTY. Please check feature engineering logic.\n"
            )
    else:
        with open(path, "w", encoding = "utf - 8") as f:
            json.dump(features, f, ensure_ascii = False, indent = 2)
        logging.info(
            "[QA] features_main.json saved successfully (%d features).", len(features)
        )
    return path


def save_features_json(features, model_name, output_dir):
    """Save feature list for a specific model name."""
    out_dir = output_dir if output_dir else "output_default"
    os.makedirs(out_dir, exist_ok = True)
    path = os.path.join(out_dir, f"features_{model_name}.json")
    with open(path, "w", encoding = "utf - 8") as f:
        json.dump(
            features if features is not None else [], f, ensure_ascii = False, indent = 2
        )
    return path


def ensure_model_files_exist(output_dir, base_trade_log_path, base_m1_data_path):
    """Ensure all model and feature files exist or auto - train with robust fallbacks."""

    logging.info("\n -  - - üîß Robust Model Files Check - -  - ")

    # Use the robust loader which creates working placeholder models
    status = ensure_model_files_robust(output_dir)

    if status["all_success"]:
        logging.info("‚úÖ All model files ready for production use!")
        return True
    else:
        logging.warning("‚ö†Ô∏è Some model files created as placeholders")
        # Even with placeholders, we can continue - they're functional
        return True